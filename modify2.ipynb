{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "020fd130-d5fd-43bb-893c-2352b43d1ece",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# 전처리\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import random\n",
    "\n",
    "# 모델\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from tensorflow import keras\n",
    "\n",
    "# 시각화 툴\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "#tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        # Currently, memory growth needs to be the same across GPUs\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        # Memory growth must be set before GPUs have been initialized\n",
    "        print(e)\n",
    "        \n",
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fded7071-3a8a-487f-ae48-8d0bfdcdf11a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_path = './content/train.csv'\n",
    "y_train_path = './content/train_label.csv'\n",
    "x_test_path = './content/test.csv'\n",
    "\n",
    "x_train = pd.read_csv(x_train_path)\n",
    "x_test = pd.read_csv(x_test_path)\n",
    "y_train = pd.read_csv(y_train_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c9e44cf6-6e19-4b2f-9bd1-87af3115efb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_series_length = pd.concat([x_train['EMAIL'].value_counts()])\n",
    "shortest_length = time_series_length[-1]\n",
    "\n",
    "arranged_labels = []\n",
    "for id in x_train['EMAIL'].unique():\n",
    "    idx = x_train['EMAIL'][x_train['EMAIL'] == id].index\n",
    "    start_idx = idx[0]\n",
    "    end_idx = idx[-1]\n",
    "    x_train.drop(list((range(start_idx + shortest_length, end_idx+1))), axis=0, inplace=True)\n",
    "    x_train = x_train.reset_index(drop=True)\n",
    "    label_idx = y_train['SAMPLE_EMAIL'][y_train['SAMPLE_EMAIL'] == id].index[0]\n",
    "    arranged_labels.append(y_train['DIAG_NM'][label_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c9b51f58-db06-4c56-aa75-9f2614f165a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for id in x_test['EMAIL'].unique():\n",
    "    idx = x_test['EMAIL'][x_test['EMAIL'] == id].index\n",
    "    start_idx = idx[0]\n",
    "    end_idx = idx[-1]\n",
    "    x_test.drop(list((range(start_idx + shortest_length, end_idx+1))), axis=0, inplace=True)\n",
    "    x_test = x_test.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "85d75096-38aa-4ef4-bbba-12647a1b6f44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5180, 65)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "21ef68c1-738d-48b4-afe7-37e6cc8afe37",
   "metadata": {},
   "outputs": [],
   "source": [
    "#x_train = pd.read_csv(x_train_path)\n",
    "#x_test = pd.read_csv(x_test_path)\n",
    "x_train_org = x_train\n",
    "x_test_org = x_test\n",
    "\n",
    "\n",
    "# 불필요한 컬럼 제거 작업 'EMAIL',\n",
    "drop = ['summary_date', 'EMAIL','activity_class_5min','activity_met_1min', 'sleep_hr_5min', 'sleep_hypnogram_5min',\n",
    "        'sleep_is_longest', 'sleep_rmssd_5min', 'timezone', 'sleep_total','sleep_temperature_trend_deviation', \n",
    "        'CONVERT(activity_class_5min USING utf8)','CONVERT(activity_met_1min USING utf8)', 'CONVERT(sleep_hr_5min USING utf8)',\n",
    "        'CONVERT(sleep_hypnogram_5min USING utf8)','CONVERT(sleep_rmssd_5min USING utf8)','activity_average_met', 'activity_cal_active', 'activity_cal_total','activity_steps', 'activity_score',\n",
    "        'activity_score_move_every_hour', 'activity_daily_movement','activity_met_min_high',\n",
    "        'activity_score_stay_active', 'activity_total', 'activity_met_min_low','activity_medium',\n",
    "        'activity_score_training_frequency','activity_steps', 'activity_score',\n",
    "        'activity_score_training_volume','sleep_efficiency','sleep_duration','sleep_hr_lowest',\n",
    "        'sleep_midpoint_time','sleep_awake','sleep_deep','sleep_rem','sleep_restless','sleep_temperature_delta',\n",
    "        'sleep_score_total','sleep_score','activity_score_meet_daily_targets','sleep_period_id','activity_inactivity_alerts',\n",
    "        'activity_score_recovery_time','sleep_score_latency', 'sleep_score_alignment', 'sleep_score_efficiency']\n",
    "x_train = x_train.drop(columns = drop)\n",
    "test_email = x_test['EMAIL']\n",
    "x_test = x_test.drop(columns = drop)\n",
    "\n",
    "\n",
    "# month 추가\n",
    "for i in range (0,len(x_train_org.iloc[:,1])):\n",
    "  date = x_train_org['summary_date']\n",
    "  temp = date[i].split('-')\n",
    "  x_train.loc[i,'month'] = temp[1]\n",
    "  \n",
    "for i in range (0,len(x_test_org.iloc[:,1])):\n",
    "  date = x_test_org['summary_date']\n",
    "  temp = date[i].split('-')\n",
    "  x_test.loc[i,'month'] = temp[1]\n",
    "\n",
    "# 시계열 자료 수치화 보조 함수\n",
    "def sumsquare_exp(llist):\n",
    "  sum = 0\n",
    "  #j = 2\n",
    "  for i in llist:\n",
    "    sum += np.exp(i)\n",
    "  return sum\n",
    "def sumsquare(llist):\n",
    "  sum = 0\n",
    "  j = 3\n",
    "  for i in llist:\n",
    "    sum = sum + i ** j # i 의 j제곱\n",
    "  return sum\n",
    "def interpolate(x):\n",
    "    temp = x.split('/')[:-1]\n",
    "    temp = pd.to_numeric(temp)\n",
    "    temp = pd.Series(temp).astype('float').replace(0., np.NaN).interpolate().tolist()\n",
    "    temp = [x for x in temp if np.isnan(x) == False]\n",
    "    return temp \n",
    "## convert new features 추가\n",
    "convert_low = ['CONVERT(activity_met_1min USING utf8)']\n",
    "convert = ['CONVERT(sleep_hypnogram_5min USING utf8)']\n",
    "for i in convert_low:\n",
    "  x_train_org.loc[:,i] = x_train_org[i].apply(interpolate)\n",
    "  x_test_org.loc[:,i] = x_test_org[i].apply(interpolate)\n",
    "  for j in range (0,len(x_train_org.iloc[:,1])):\n",
    "    x_train.loc[j, 'new_' + i] = sumsquare_exp(x_train_org.loc[j,i]) / len(x_train_org.loc[j,i])\n",
    "  for k in range (0,len(x_test_org.iloc[:,1])):\n",
    "    x_test.loc[k, 'new_' + i] = sumsquare_exp(x_test_org.loc[k,i]) / len(x_test_org.loc[k,i])\n",
    "for i in convert:\n",
    "  x_train_org.loc[:,i] = x_train_org[i].apply(interpolate)\n",
    "  x_test_org.loc[:,i] = x_test_org[i].apply(interpolate)\n",
    "  for j in range (0,len(x_train_org.iloc[:,1])):\n",
    "    x_train.loc[j, 'new_' + i] = sumsquare(x_train_org.loc[j,i]) / len(x_train_org.loc[j,i])\n",
    "  for k in range (0,len(x_test_org.iloc[:,1])):\n",
    "    x_test.loc[k, 'new_' + i] = sumsquare(x_test_org.loc[k,i]) / len(x_test_org.loc[k,i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ed4e9235-47e7-427f-b45c-65b975b0ccd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16485, 20)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "417ed64b-dd26-41f8-ac87-8f920353c7b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5180, 20)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3e26d11c-5c3f-43a3-b96a-ff56e21cd518",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(x_train)\n",
    "x_train = scaler.transform(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4a7aa99e-9988-45ba-b75f-16a100a036f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "arranged_labels = np.reshape(arranged_labels,(-1,1))\n",
    "le = OneHotEncoder()\n",
    "le.fit(arranged_labels)\n",
    "arranged_labels = le.fit_transform(arranged_labels).toarray()\n",
    "y = arranged_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8e451e00-cc16-489b-a345-93edbde2dc70",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = x_train.reshape((148,35,20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3e5ffd10-340c-446e-8afe-ac2c91b894a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\leePC\\anaconda3\\envs\\tf2.4\\lib\\site-packages\\sklearn\\utils\\validation.py:72: FutureWarning:\n",
      "\n",
      "Pass classes=[0 1 2], y=[0 2 2 0 2 0 2 0 2 0 0 2 1 0 0 0 0 2 2 0 2 0 0 0 2 1 0 1 0 2 0 2 2 0 0 2 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 2 2 0 0 2 0 0 0 0 1 2 0 0 2 0 1 0 0 2 0 0\n",
      " 0 0 1 0 0 2 2 0 0 0 2 0 2 0 2 0 0 1 0 0 0 0 2 2 2 0 2 0 0 0 0 0 1 2 2 2 0\n",
      " 2 2 0 0 0 0 2 0 0 2 2 0 0 0 1 0 2 1 0 0 2 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0] as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "y_integers = np.argmax(y, axis=1)\n",
    "class_weights = compute_class_weight('balanced', np.unique(y_integers), y_integers)\n",
    "d_class_weights = dict(enumerate(class_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "889ddde1-5b82-4743-a609-bcee3088d43b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, LSTM, Conv1D, MaxPooling1D, Dropout, Flatten, BatchNormalization, Input, Convolution2D, Activation,TimeDistributed\n",
    "from keras.layers import Input, multiply, concatenate, Activation, Masking, Reshape\n",
    "from keras.layers import GlobalAveragePooling1D, Permute, Dropout\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9ae0766c-9fb7-457a-9cea-c63114b4e761",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(None, 35, 20)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)             (None, 700, 1)       0           input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, 233, 64)      256         reshape_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 233, 64)      256         conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 233, 64)      0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_4 (Conv1D)               (None, 233, 128)     24704       activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 233, 128)     512         conv1d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 233, 128)     0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1D)  (None, 77, 128)      0           activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_5 (Conv1D)               (None, 77, 64)       24640       max_pooling1d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 77, 64)       256         conv1d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "masking_1 (Masking)             (None, 35, 20)       0           input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 77, 64)       0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   (None, 35, 50)       14200       masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1D)  (None, 25, 64)       0           activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "lstm_3 (LSTM)                   (None, 50)           20200       lstm_2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 25, 64)       0           max_pooling1d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 50)           0           lstm_3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 1600)         0           dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 1650)         0           dropout_3[0][0]                  \n",
      "                                                                 flatten_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 3)            4953        concatenate_1[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 89,977\n",
      "Trainable params: 89,465\n",
      "Non-trainable params: 512\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def generate_model():\n",
    "    ip = Input(shape=(35, 20))\n",
    "\n",
    "    x = Masking()(ip)\n",
    "    x = LSTM(units = 50, return_sequences = True)(x)\n",
    "    x = LSTM(units=50)(x)\n",
    "    x = Dropout(0.8)(x)\n",
    "\n",
    "  \n",
    "    y = Reshape((700,1))(ip)\n",
    "    y = Conv1D (kernel_size=3, filters=64, strides=3, padding='valid',kernel_initializer='he_uniform')(y)\n",
    "    y = BatchNormalization()(y)\n",
    "    y = Activation('relu')(y)\n",
    "\n",
    "    \n",
    "    y = Conv1D (kernel_size=3, filters=128, padding='same', kernel_initializer='he_uniform')(y)\n",
    "    y = BatchNormalization()(y)\n",
    "    y = Activation('relu')(y)\n",
    "    y = MaxPooling1D(pool_size=3, strides=3)(y)\n",
    "\n",
    "    y = Conv1D (kernel_size=3, filters=64, padding='same', kernel_initializer='he_uniform')(y)\n",
    "    y = BatchNormalization()(y)\n",
    "    y = Activation('relu')(y)\n",
    "    y = MaxPooling1D(pool_size=3, strides=3)(y)\n",
    "\n",
    "    \n",
    "    y = Dropout(0.8)(y)\n",
    "    y = Flatten()(y)\n",
    "    \n",
    "    x = concatenate([x, y])\n",
    "\n",
    "    out = Dense(3, activation='softmax')(x)\n",
    "\n",
    "    model = Model(ip, out)\n",
    "    #model.summary()\n",
    "    return model\n",
    "model = generate_model()\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "73ac7633-8b41-4b6d-9ece-af90887d5e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=4321)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d1790f37-9bf8-4e14-acc7-0702aa5fb72d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "4/4 [==============================] - 10s 983ms/step - loss: 3.3444 - accuracy: 0.4429 - val_loss: 1.1971 - val_accuracy: 0.6667\n",
      "Epoch 2/300\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 3.0269 - accuracy: 0.3974 - val_loss: 1.1377 - val_accuracy: 0.6667\n",
      "Epoch 3/300\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 4.2807 - accuracy: 0.3945 - val_loss: 1.1120 - val_accuracy: 0.6667\n",
      "Epoch 4/300\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 3.4777 - accuracy: 0.4335 - val_loss: 1.1355 - val_accuracy: 0.6000\n",
      "Epoch 5/300\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 2.5305 - accuracy: 0.4424 - val_loss: 1.2040 - val_accuracy: 0.5333\n",
      "Epoch 6/300\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 2.8319 - accuracy: 0.3968 - val_loss: 1.2985 - val_accuracy: 0.5333\n",
      "Epoch 7/300\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 2.6360 - accuracy: 0.3348 - val_loss: 1.3855 - val_accuracy: 0.4333\n",
      "Epoch 8/300\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 3.2473 - accuracy: 0.3200 - val_loss: 1.4346 - val_accuracy: 0.4000\n",
      "Epoch 9/300\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 2.7963 - accuracy: 0.4317 - val_loss: 1.4842 - val_accuracy: 0.3000\n",
      "Epoch 10/300\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 2.8853 - accuracy: 0.4362 - val_loss: 1.5296 - val_accuracy: 0.3000\n",
      "Epoch 11/300\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 1.8276 - accuracy: 0.4716 - val_loss: 1.5782 - val_accuracy: 0.3000\n",
      "Epoch 12/300\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 2.0546 - accuracy: 0.3794 - val_loss: 1.6121 - val_accuracy: 0.3000\n",
      "Epoch 13/300\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 3.0067 - accuracy: 0.3406 - val_loss: 1.6384 - val_accuracy: 0.2667\n",
      "Epoch 14/300\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 2.4687 - accuracy: 0.3262 - val_loss: 1.6538 - val_accuracy: 0.2667\n",
      "Epoch 15/300\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 2.7069 - accuracy: 0.3906 - val_loss: 1.6951 - val_accuracy: 0.2667\n",
      "Epoch 16/300\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 2.1299 - accuracy: 0.4534 - val_loss: 1.7149 - val_accuracy: 0.2667\n",
      "Epoch 17/300\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 3.0107 - accuracy: 0.4427 - val_loss: 1.7664 - val_accuracy: 0.2667\n",
      "Epoch 18/300\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 2.7039 - accuracy: 0.3973 - val_loss: 1.8077 - val_accuracy: 0.2333\n",
      "Epoch 19/300\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 2.2106 - accuracy: 0.3802 - val_loss: 1.8468 - val_accuracy: 0.2667\n",
      "Epoch 20/300\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 2.4588 - accuracy: 0.4237 - val_loss: 1.8633 - val_accuracy: 0.2667\n",
      "Epoch 21/300\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 1.9543 - accuracy: 0.4073 - val_loss: 1.8861 - val_accuracy: 0.2667\n",
      "Epoch 22/300\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 2.4011 - accuracy: 0.3619 - val_loss: 1.9103 - val_accuracy: 0.2667\n",
      "Epoch 23/300\n",
      "4/4 [==============================] - 0s 113ms/step - loss: 2.5439 - accuracy: 0.4447 - val_loss: 1.9397 - val_accuracy: 0.3000\n",
      "Epoch 24/300\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 2.4259 - accuracy: 0.4424 - val_loss: 1.9691 - val_accuracy: 0.3000\n",
      "Epoch 25/300\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 2.6145 - accuracy: 0.3377 - val_loss: 1.9845 - val_accuracy: 0.3000\n",
      "Epoch 26/300\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 1.7367 - accuracy: 0.4328 - val_loss: 1.9714 - val_accuracy: 0.3000\n",
      "Epoch 27/300\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 1.9025 - accuracy: 0.4632 - val_loss: 1.9570 - val_accuracy: 0.3000\n",
      "Epoch 28/300\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 1.7842 - accuracy: 0.4401 - val_loss: 1.9240 - val_accuracy: 0.3000\n",
      "Epoch 29/300\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 2.1403 - accuracy: 0.4341 - val_loss: 1.8845 - val_accuracy: 0.3000\n",
      "Epoch 30/300\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 1.6945 - accuracy: 0.4422 - val_loss: 1.8488 - val_accuracy: 0.3000\n",
      "Epoch 31/300\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 2.8766 - accuracy: 0.4513 - val_loss: 1.8621 - val_accuracy: 0.3000\n",
      "Epoch 32/300\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 1.6432 - accuracy: 0.4315 - val_loss: 1.9165 - val_accuracy: 0.3000\n",
      "Epoch 33/300\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 2.1814 - accuracy: 0.4489 - val_loss: 1.9411 - val_accuracy: 0.2667\n",
      "Epoch 34/300\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 1.9273 - accuracy: 0.4750 - val_loss: 1.9407 - val_accuracy: 0.2667\n",
      "Epoch 35/300\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 1.4317 - accuracy: 0.3830 - val_loss: 1.8913 - val_accuracy: 0.2667\n",
      "Epoch 36/300\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 1.7302 - accuracy: 0.4422 - val_loss: 1.8444 - val_accuracy: 0.3000\n",
      "Epoch 37/300\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 2.1039 - accuracy: 0.4948 - val_loss: 1.8383 - val_accuracy: 0.3000\n",
      "Epoch 38/300\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 1.5162 - accuracy: 0.4541 - val_loss: 1.8082 - val_accuracy: 0.3000\n",
      "Epoch 39/300\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 1.9040 - accuracy: 0.3908 - val_loss: 1.7510 - val_accuracy: 0.3000\n",
      "Epoch 40/300\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 1.9622 - accuracy: 0.5190 - val_loss: 1.6988 - val_accuracy: 0.3000\n",
      "Epoch 41/300\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 1.8281 - accuracy: 0.4724 - val_loss: 1.6838 - val_accuracy: 0.3000\n",
      "Epoch 42/300\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 1.2566 - accuracy: 0.4382 - val_loss: 1.6667 - val_accuracy: 0.3333\n",
      "Epoch 43/300\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 1.9186 - accuracy: 0.3692 - val_loss: 1.6439 - val_accuracy: 0.3333\n",
      "Epoch 44/300\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 1.3429 - accuracy: 0.6013 - val_loss: 1.6391 - val_accuracy: 0.3333\n",
      "Epoch 45/300\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 1.1287 - accuracy: 0.4700 - val_loss: 1.6056 - val_accuracy: 0.3667\n",
      "Epoch 46/300\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 1.5525 - accuracy: 0.4453 - val_loss: 1.5518 - val_accuracy: 0.3667\n",
      "Epoch 47/300\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 1.9116 - accuracy: 0.4245 - val_loss: 1.5154 - val_accuracy: 0.3667\n",
      "Epoch 48/300\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 1.3720 - accuracy: 0.4270 - val_loss: 1.4722 - val_accuracy: 0.4000\n",
      "Epoch 49/300\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 1.5390 - accuracy: 0.4341 - val_loss: 1.4331 - val_accuracy: 0.4000\n",
      "Epoch 50/300\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 1.1384 - accuracy: 0.6389 - val_loss: 1.3940 - val_accuracy: 0.4000\n",
      "Epoch 51/300\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 1.5172 - accuracy: 0.4544 - val_loss: 1.3628 - val_accuracy: 0.4000\n",
      "Epoch 52/300\n",
      "4/4 [==============================] - 0s 114ms/step - loss: 1.4238 - accuracy: 0.5396 - val_loss: 1.3758 - val_accuracy: 0.3667\n",
      "Epoch 53/300\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 1.1256 - accuracy: 0.5130 - val_loss: 1.3876 - val_accuracy: 0.3667\n",
      "Epoch 54/300\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 1.4157 - accuracy: 0.4859 - val_loss: 1.3974 - val_accuracy: 0.3667\n",
      "Epoch 55/300\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 1.3248 - accuracy: 0.5584 - val_loss: 1.4117 - val_accuracy: 0.3667\n",
      "Epoch 56/300\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 1.4696 - accuracy: 0.4698 - val_loss: 1.4229 - val_accuracy: 0.3667\n",
      "Epoch 57/300\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 1.1409 - accuracy: 0.5956 - val_loss: 1.4367 - val_accuracy: 0.3667\n",
      "Epoch 58/300\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 1.5342 - accuracy: 0.5487 - val_loss: 1.4279 - val_accuracy: 0.3667\n",
      "Epoch 59/300\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 1.6641 - accuracy: 0.5388 - val_loss: 1.4176 - val_accuracy: 0.3667\n",
      "Epoch 60/300\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 1.0059 - accuracy: 0.5683 - val_loss: 1.3902 - val_accuracy: 0.3667\n",
      "Epoch 61/300\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 1.2505 - accuracy: 0.4500 - val_loss: 1.3551 - val_accuracy: 0.3667\n",
      "Epoch 62/300\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 1.3214 - accuracy: 0.5130 - val_loss: 1.3197 - val_accuracy: 0.4333\n",
      "Epoch 63/300\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 1.0094 - accuracy: 0.6548 - val_loss: 1.3011 - val_accuracy: 0.4333\n",
      "Epoch 64/300\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 1.0420 - accuracy: 0.5836 - val_loss: 1.2822 - val_accuracy: 0.4667\n",
      "Epoch 65/300\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 1.4168 - accuracy: 0.5732 - val_loss: 1.2799 - val_accuracy: 0.5000\n",
      "Epoch 66/300\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 1.3597 - accuracy: 0.5456 - val_loss: 1.2766 - val_accuracy: 0.5000\n",
      "Epoch 67/300\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 1.0689 - accuracy: 0.6053 - val_loss: 1.2846 - val_accuracy: 0.4667\n",
      "Epoch 68/300\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 1.2815 - accuracy: 0.5680 - val_loss: 1.2813 - val_accuracy: 0.4667\n",
      "Epoch 69/300\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 1.2664 - accuracy: 0.5459 - val_loss: 1.2846 - val_accuracy: 0.4667\n",
      "Epoch 70/300\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 1.4369 - accuracy: 0.5519 - val_loss: 1.2839 - val_accuracy: 0.4667\n",
      "Epoch 71/300\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 1.2932 - accuracy: 0.5414 - val_loss: 1.2843 - val_accuracy: 0.4667\n",
      "Epoch 72/300\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.9389 - accuracy: 0.6235 - val_loss: 1.2921 - val_accuracy: 0.4667\n",
      "Epoch 73/300\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 1.0096 - accuracy: 0.5487 - val_loss: 1.2984 - val_accuracy: 0.4667\n",
      "Epoch 74/300\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 1.0616 - accuracy: 0.6691 - val_loss: 1.3272 - val_accuracy: 0.4667\n",
      "Epoch 75/300\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 1.4243 - accuracy: 0.5138 - val_loss: 1.3649 - val_accuracy: 0.4667\n",
      "Epoch 76/300\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 1.1220 - accuracy: 0.5774 - val_loss: 1.3745 - val_accuracy: 0.4667\n",
      "Epoch 77/300\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 1.3511 - accuracy: 0.5399 - val_loss: 1.3623 - val_accuracy: 0.4667\n",
      "Epoch 78/300\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.9818 - accuracy: 0.6933 - val_loss: 1.3501 - val_accuracy: 0.4667\n",
      "Epoch 79/300\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.8620 - accuracy: 0.6279 - val_loss: 1.3472 - val_accuracy: 0.4667\n",
      "Epoch 80/300\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.9999 - accuracy: 0.6058 - val_loss: 1.3455 - val_accuracy: 0.4333\n",
      "Epoch 81/300\n",
      "4/4 [==============================] - 0s 113ms/step - loss: 0.8597 - accuracy: 0.6670 - val_loss: 1.3456 - val_accuracy: 0.4333\n",
      "Epoch 82/300\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 1.1541 - accuracy: 0.6081 - val_loss: 1.3407 - val_accuracy: 0.4333\n",
      "Epoch 83/300\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.8739 - accuracy: 0.6670 - val_loss: 1.3437 - val_accuracy: 0.4333\n",
      "Epoch 84/300\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.9333 - accuracy: 0.6696 - val_loss: 1.3502 - val_accuracy: 0.4000\n",
      "Epoch 85/300\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.7262 - accuracy: 0.7199 - val_loss: 1.3577 - val_accuracy: 0.4000\n",
      "Epoch 86/300\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 1.1874 - accuracy: 0.6407 - val_loss: 1.3721 - val_accuracy: 0.3667\n",
      "Epoch 87/300\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 1.0543 - accuracy: 0.5771 - val_loss: 1.3752 - val_accuracy: 0.3667\n",
      "Epoch 88/300\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.9307 - accuracy: 0.6790 - val_loss: 1.3706 - val_accuracy: 0.3667\n",
      "Epoch 89/300\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 1.2667 - accuracy: 0.6188 - val_loss: 1.3680 - val_accuracy: 0.3667\n",
      "Epoch 90/300\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.8359 - accuracy: 0.7022 - val_loss: 1.3711 - val_accuracy: 0.3667\n",
      "Epoch 91/300\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.9663 - accuracy: 0.5896 - val_loss: 1.3676 - val_accuracy: 0.3667\n",
      "Epoch 92/300\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.8305 - accuracy: 0.6608 - val_loss: 1.3541 - val_accuracy: 0.4000\n",
      "Epoch 93/300\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.9177 - accuracy: 0.6524 - val_loss: 1.3514 - val_accuracy: 0.4000\n",
      "Epoch 94/300\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 1.1845 - accuracy: 0.5594 - val_loss: 1.3753 - val_accuracy: 0.3667\n",
      "Epoch 95/300\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.9972 - accuracy: 0.6248 - val_loss: 1.3836 - val_accuracy: 0.3667\n",
      "Epoch 96/300\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.9353 - accuracy: 0.6204 - val_loss: 1.3850 - val_accuracy: 0.3667\n",
      "Epoch 97/300\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.7756 - accuracy: 0.6696 - val_loss: 1.3815 - val_accuracy: 0.3667\n",
      "Epoch 98/300\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.6535 - accuracy: 0.6652 - val_loss: 1.3802 - val_accuracy: 0.4000\n",
      "Epoch 99/300\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.8420 - accuracy: 0.6227 - val_loss: 1.3835 - val_accuracy: 0.4000\n",
      "Epoch 100/300\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 1.2796 - accuracy: 0.6410 - val_loss: 1.3826 - val_accuracy: 0.4000\n",
      "Epoch 101/300\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 1.0192 - accuracy: 0.5842 - val_loss: 1.3840 - val_accuracy: 0.4000\n",
      "Epoch 102/300\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.7357 - accuracy: 0.6621 - val_loss: 1.3811 - val_accuracy: 0.4000\n",
      "Epoch 103/300\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 1.0893 - accuracy: 0.6154 - val_loss: 1.3787 - val_accuracy: 0.4000\n",
      "Epoch 104/300\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.8366 - accuracy: 0.6493 - val_loss: 1.3854 - val_accuracy: 0.4000\n",
      "Epoch 105/300\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.9811 - accuracy: 0.6587 - val_loss: 1.3968 - val_accuracy: 0.4000\n",
      "Epoch 106/300\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 1.1310 - accuracy: 0.5662 - val_loss: 1.4171 - val_accuracy: 0.4000\n",
      "Epoch 107/300\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.7556 - accuracy: 0.6506 - val_loss: 1.4160 - val_accuracy: 0.4000\n",
      "Epoch 108/300\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.7774 - accuracy: 0.6813 - val_loss: 1.4082 - val_accuracy: 0.4000\n",
      "Epoch 109/300\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.8455 - accuracy: 0.6527 - val_loss: 1.4010 - val_accuracy: 0.4000\n",
      "Epoch 110/300\n",
      "4/4 [==============================] - 0s 114ms/step - loss: 1.0467 - accuracy: 0.6503 - val_loss: 1.4010 - val_accuracy: 0.4000\n",
      "Epoch 111/300\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.8234 - accuracy: 0.6344 - val_loss: 1.4120 - val_accuracy: 0.4000\n",
      "Epoch 112/300\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 1.1519 - accuracy: 0.6954 - val_loss: 1.3925 - val_accuracy: 0.4000\n",
      "Epoch 113/300\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.9727 - accuracy: 0.6897 - val_loss: 1.3870 - val_accuracy: 0.4000\n",
      "Epoch 114/300\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 1.3628 - accuracy: 0.6003 - val_loss: 1.3802 - val_accuracy: 0.4000\n",
      "Epoch 115/300\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.7809 - accuracy: 0.6438 - val_loss: 1.3499 - val_accuracy: 0.4000\n",
      "Epoch 116/300\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.8021 - accuracy: 0.6256 - val_loss: 1.3272 - val_accuracy: 0.4000\n",
      "Epoch 117/300\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.6028 - accuracy: 0.6610 - val_loss: 1.3052 - val_accuracy: 0.4000\n",
      "Epoch 118/300\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.8524 - accuracy: 0.6423 - val_loss: 1.3012 - val_accuracy: 0.4000\n",
      "Epoch 119/300\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.8076 - accuracy: 0.6378 - val_loss: 1.3099 - val_accuracy: 0.4000\n",
      "Epoch 120/300\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 1.0519 - accuracy: 0.5628 - val_loss: 1.3230 - val_accuracy: 0.4000\n",
      "Epoch 121/300\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.7134 - accuracy: 0.6704 - val_loss: 1.3233 - val_accuracy: 0.4000\n",
      "Epoch 122/300\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.7441 - accuracy: 0.6537 - val_loss: 1.3264 - val_accuracy: 0.4000\n",
      "Epoch 123/300\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.7194 - accuracy: 0.6629 - val_loss: 1.3314 - val_accuracy: 0.4000\n",
      "Epoch 124/300\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.9244 - accuracy: 0.5855 - val_loss: 1.3441 - val_accuracy: 0.4000\n",
      "Epoch 125/300\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.6390 - accuracy: 0.6730 - val_loss: 1.3521 - val_accuracy: 0.4000\n",
      "Epoch 126/300\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.8264 - accuracy: 0.7452 - val_loss: 1.3320 - val_accuracy: 0.4000\n",
      "Epoch 127/300\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.9438 - accuracy: 0.6514 - val_loss: 1.3253 - val_accuracy: 0.4000\n",
      "Epoch 128/300\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.7995 - accuracy: 0.6256 - val_loss: 1.3051 - val_accuracy: 0.4000\n",
      "Epoch 129/300\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.5733 - accuracy: 0.7832 - val_loss: 1.2677 - val_accuracy: 0.4000\n",
      "Epoch 130/300\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.6575 - accuracy: 0.7366 - val_loss: 1.2381 - val_accuracy: 0.4000\n",
      "Epoch 131/300\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.6291 - accuracy: 0.6946 - val_loss: 1.2234 - val_accuracy: 0.4333\n",
      "Epoch 132/300\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.7735 - accuracy: 0.7322 - val_loss: 1.2240 - val_accuracy: 0.4333\n",
      "Epoch 133/300\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.6025 - accuracy: 0.7561 - val_loss: 1.2262 - val_accuracy: 0.4333\n",
      "Epoch 134/300\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.7793 - accuracy: 0.6490 - val_loss: 1.2243 - val_accuracy: 0.4667\n",
      "Epoch 135/300\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.7518 - accuracy: 0.6699 - val_loss: 1.2321 - val_accuracy: 0.4333\n",
      "Epoch 136/300\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.6176 - accuracy: 0.7001 - val_loss: 1.2418 - val_accuracy: 0.4333\n",
      "Epoch 137/300\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.7382 - accuracy: 0.7366 - val_loss: 1.2547 - val_accuracy: 0.4000\n",
      "Epoch 138/300\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.6882 - accuracy: 0.6777 - val_loss: 1.2592 - val_accuracy: 0.4000\n",
      "Epoch 139/300\n",
      "4/4 [==============================] - 0s 116ms/step - loss: 1.0044 - accuracy: 0.7037 - val_loss: 1.2531 - val_accuracy: 0.4000\n",
      "Epoch 140/300\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.9051 - accuracy: 0.6519 - val_loss: 1.2527 - val_accuracy: 0.4000\n",
      "Epoch 141/300\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.6920 - accuracy: 0.6915 - val_loss: 1.2511 - val_accuracy: 0.4000\n",
      "Epoch 142/300\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.7009 - accuracy: 0.6928 - val_loss: 1.2551 - val_accuracy: 0.4000\n",
      "Epoch 143/300\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.8544 - accuracy: 0.6087 - val_loss: 1.2663 - val_accuracy: 0.4000\n",
      "Epoch 144/300\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.7272 - accuracy: 0.7337 - val_loss: 1.2846 - val_accuracy: 0.4000\n",
      "Epoch 145/300\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.4779 - accuracy: 0.7652 - val_loss: 1.2884 - val_accuracy: 0.4000\n",
      "Epoch 146/300\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.4579 - accuracy: 0.7327 - val_loss: 1.2790 - val_accuracy: 0.4000\n",
      "Epoch 147/300\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.8059 - accuracy: 0.6941 - val_loss: 1.2849 - val_accuracy: 0.4000\n",
      "Epoch 148/300\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.6987 - accuracy: 0.7058 - val_loss: 1.2873 - val_accuracy: 0.4000\n",
      "Epoch 149/300\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.7344 - accuracy: 0.6206 - val_loss: 1.2827 - val_accuracy: 0.4000\n",
      "Epoch 150/300\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.7237 - accuracy: 0.7472 - val_loss: 1.2827 - val_accuracy: 0.4000\n",
      "Epoch 151/300\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.7393 - accuracy: 0.6910 - val_loss: 1.2758 - val_accuracy: 0.4000\n",
      "Epoch 152/300\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.7209 - accuracy: 0.6782 - val_loss: 1.2586 - val_accuracy: 0.4333\n",
      "Epoch 153/300\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.6577 - accuracy: 0.6047 - val_loss: 1.2439 - val_accuracy: 0.4667\n",
      "Epoch 154/300\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.5205 - accuracy: 0.7108 - val_loss: 1.2379 - val_accuracy: 0.4667\n",
      "Epoch 155/300\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.5971 - accuracy: 0.7866 - val_loss: 1.2358 - val_accuracy: 0.5000\n",
      "Epoch 156/300\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.7935 - accuracy: 0.7058 - val_loss: 1.2473 - val_accuracy: 0.4667\n",
      "Epoch 157/300\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.6266 - accuracy: 0.7441 - val_loss: 1.2698 - val_accuracy: 0.4333\n",
      "Epoch 158/300\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.4747 - accuracy: 0.8012 - val_loss: 1.2874 - val_accuracy: 0.4333\n",
      "Epoch 159/300\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.4054 - accuracy: 0.7955 - val_loss: 1.3030 - val_accuracy: 0.4333\n",
      "Epoch 160/300\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.9090 - accuracy: 0.7316 - val_loss: 1.3097 - val_accuracy: 0.4333\n",
      "Epoch 161/300\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.4163 - accuracy: 0.7382 - val_loss: 1.3078 - val_accuracy: 0.4333\n",
      "Epoch 162/300\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.6710 - accuracy: 0.7155 - val_loss: 1.2804 - val_accuracy: 0.4333\n",
      "Epoch 163/300\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.5471 - accuracy: 0.7111 - val_loss: 1.2666 - val_accuracy: 0.4333\n",
      "Epoch 164/300\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.6102 - accuracy: 0.7473 - val_loss: 1.2613 - val_accuracy: 0.4333\n",
      "Epoch 165/300\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.7164 - accuracy: 0.7025 - val_loss: 1.2664 - val_accuracy: 0.4333\n",
      "Epoch 166/300\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.7028 - accuracy: 0.7626 - val_loss: 1.2677 - val_accuracy: 0.4333\n",
      "Epoch 167/300\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.4884 - accuracy: 0.7645 - val_loss: 1.2766 - val_accuracy: 0.4333\n",
      "Epoch 168/300\n",
      "4/4 [==============================] - 0s 113ms/step - loss: 0.7485 - accuracy: 0.6868 - val_loss: 1.2891 - val_accuracy: 0.4333\n",
      "Epoch 169/300\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.5822 - accuracy: 0.7663 - val_loss: 1.2825 - val_accuracy: 0.4333\n",
      "Epoch 170/300\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.6356 - accuracy: 0.7637 - val_loss: 1.2839 - val_accuracy: 0.4333\n",
      "Epoch 171/300\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.3617 - accuracy: 0.8280 - val_loss: 1.2883 - val_accuracy: 0.4333\n",
      "Epoch 172/300\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.6246 - accuracy: 0.6417 - val_loss: 1.2895 - val_accuracy: 0.4333\n",
      "Epoch 173/300\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.4856 - accuracy: 0.7678 - val_loss: 1.2882 - val_accuracy: 0.4333\n",
      "Epoch 174/300\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.4748 - accuracy: 0.7382 - val_loss: 1.2983 - val_accuracy: 0.4333\n",
      "Epoch 175/300\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.6505 - accuracy: 0.6936 - val_loss: 1.3221 - val_accuracy: 0.4333\n",
      "Epoch 176/300\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.6438 - accuracy: 0.7658 - val_loss: 1.3451 - val_accuracy: 0.4333\n",
      "Epoch 177/300\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.5186 - accuracy: 0.7475 - val_loss: 1.3630 - val_accuracy: 0.4000\n",
      "Epoch 178/300\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.6461 - accuracy: 0.6920 - val_loss: 1.3675 - val_accuracy: 0.4000\n",
      "Epoch 179/300\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.3277 - accuracy: 0.8413 - val_loss: 1.3757 - val_accuracy: 0.4000\n",
      "Epoch 180/300\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.7089 - accuracy: 0.7444 - val_loss: 1.3766 - val_accuracy: 0.4000\n",
      "Epoch 181/300\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.5007 - accuracy: 0.7801 - val_loss: 1.3630 - val_accuracy: 0.4000\n",
      "Epoch 182/300\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.3991 - accuracy: 0.7903 - val_loss: 1.3493 - val_accuracy: 0.4333\n",
      "Epoch 183/300\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.6449 - accuracy: 0.6678 - val_loss: 1.3265 - val_accuracy: 0.4333\n",
      "Epoch 184/300\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.5820 - accuracy: 0.7157 - val_loss: 1.3198 - val_accuracy: 0.4333\n",
      "Epoch 185/300\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.6001 - accuracy: 0.7238 - val_loss: 1.3183 - val_accuracy: 0.4333\n",
      "Epoch 186/300\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.4505 - accuracy: 0.7520 - val_loss: 1.3129 - val_accuracy: 0.4333\n",
      "Epoch 187/300\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.4151 - accuracy: 0.8351 - val_loss: 1.3045 - val_accuracy: 0.4333\n",
      "Epoch 188/300\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.4052 - accuracy: 0.8035 - val_loss: 1.3058 - val_accuracy: 0.4333\n",
      "Epoch 189/300\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.4223 - accuracy: 0.8174 - val_loss: 1.3031 - val_accuracy: 0.5000\n",
      "Epoch 190/300\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.5289 - accuracy: 0.7564 - val_loss: 1.2982 - val_accuracy: 0.5000\n",
      "Epoch 191/300\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.4662 - accuracy: 0.7645 - val_loss: 1.2918 - val_accuracy: 0.4667\n",
      "Epoch 192/300\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.4700 - accuracy: 0.7796 - val_loss: 1.2850 - val_accuracy: 0.4667\n",
      "Epoch 193/300\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.5048 - accuracy: 0.8332 - val_loss: 1.2776 - val_accuracy: 0.5000\n",
      "Epoch 194/300\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.3833 - accuracy: 0.8452 - val_loss: 1.2762 - val_accuracy: 0.5000\n",
      "Epoch 195/300\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.5252 - accuracy: 0.7230 - val_loss: 1.2750 - val_accuracy: 0.5000\n",
      "Epoch 196/300\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.5453 - accuracy: 0.8374 - val_loss: 1.2734 - val_accuracy: 0.5000\n",
      "Epoch 197/300\n",
      "4/4 [==============================] - 0s 114ms/step - loss: 0.2944 - accuracy: 0.8325 - val_loss: 1.2827 - val_accuracy: 0.4667\n",
      "Epoch 198/300\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.4833 - accuracy: 0.7447 - val_loss: 1.2862 - val_accuracy: 0.4667\n",
      "Epoch 199/300\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.5024 - accuracy: 0.7955 - val_loss: 1.2929 - val_accuracy: 0.4333\n",
      "Epoch 200/300\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.7519 - accuracy: 0.6475 - val_loss: 1.3024 - val_accuracy: 0.4333\n",
      "Epoch 201/300\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.7566 - accuracy: 0.7447 - val_loss: 1.2939 - val_accuracy: 0.4667\n",
      "Epoch 202/300\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.5536 - accuracy: 0.7647 - val_loss: 1.2784 - val_accuracy: 0.5000\n",
      "Epoch 203/300\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.3720 - accuracy: 0.7970 - val_loss: 1.2721 - val_accuracy: 0.5667\n",
      "Epoch 204/300\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.4393 - accuracy: 0.7473 - val_loss: 1.2697 - val_accuracy: 0.6333\n",
      "Epoch 205/300\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.8164 - accuracy: 0.6715 - val_loss: 1.2696 - val_accuracy: 0.6000\n",
      "Epoch 206/300\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.3103 - accuracy: 0.8932 - val_loss: 1.2667 - val_accuracy: 0.6000\n",
      "Epoch 207/300\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.3559 - accuracy: 0.8252 - val_loss: 1.2607 - val_accuracy: 0.6000\n",
      "Epoch 208/300\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.5022 - accuracy: 0.7616 - val_loss: 1.2572 - val_accuracy: 0.5667\n",
      "Epoch 209/300\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.3162 - accuracy: 0.8359 - val_loss: 1.2511 - val_accuracy: 0.5667\n",
      "Epoch 210/300\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.3060 - accuracy: 0.8400 - val_loss: 1.2473 - val_accuracy: 0.5667\n",
      "Epoch 211/300\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.3468 - accuracy: 0.8267 - val_loss: 1.2430 - val_accuracy: 0.5667\n",
      "Epoch 212/300\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.4041 - accuracy: 0.7720 - val_loss: 1.2449 - val_accuracy: 0.5667\n",
      "Epoch 213/300\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.6739 - accuracy: 0.7553 - val_loss: 1.2477 - val_accuracy: 0.5667\n",
      "Epoch 214/300\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.3300 - accuracy: 0.8111 - val_loss: 1.2513 - val_accuracy: 0.5667\n",
      "Epoch 215/300\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.4214 - accuracy: 0.8114 - val_loss: 1.2526 - val_accuracy: 0.5667\n",
      "Epoch 216/300\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.9340 - accuracy: 0.7736 - val_loss: 1.2657 - val_accuracy: 0.5667\n",
      "Epoch 217/300\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.9340 - accuracy: 0.7574 - val_loss: 1.2982 - val_accuracy: 0.5667\n",
      "Epoch 218/300\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.3755 - accuracy: 0.8439 - val_loss: 1.3305 - val_accuracy: 0.4333\n",
      "Epoch 219/300\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.4880 - accuracy: 0.8067 - val_loss: 1.3686 - val_accuracy: 0.4333\n",
      "Epoch 220/300\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.3680 - accuracy: 0.7335 - val_loss: 1.3886 - val_accuracy: 0.4333\n",
      "Epoch 221/300\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.4516 - accuracy: 0.7767 - val_loss: 1.4003 - val_accuracy: 0.4333\n",
      "Epoch 222/300\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.4709 - accuracy: 0.7608 - val_loss: 1.3926 - val_accuracy: 0.4333\n",
      "Epoch 223/300\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.6197 - accuracy: 0.7163 - val_loss: 1.3886 - val_accuracy: 0.4333\n",
      "Epoch 224/300\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.4159 - accuracy: 0.7616 - val_loss: 1.3943 - val_accuracy: 0.4333\n",
      "Epoch 225/300\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.3310 - accuracy: 0.8137 - val_loss: 1.4066 - val_accuracy: 0.4333\n",
      "Epoch 226/300\n",
      "4/4 [==============================] - 0s 115ms/step - loss: 0.4654 - accuracy: 0.7645 - val_loss: 1.4103 - val_accuracy: 0.4333\n",
      "Epoch 227/300\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.3463 - accuracy: 0.8570 - val_loss: 1.4109 - val_accuracy: 0.4333\n",
      "Epoch 228/300\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.5389 - accuracy: 0.7835 - val_loss: 1.4163 - val_accuracy: 0.4333\n",
      "Epoch 229/300\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.3284 - accuracy: 0.7915 - val_loss: 1.4153 - val_accuracy: 0.5000\n",
      "Epoch 230/300\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.5197 - accuracy: 0.7436 - val_loss: 1.4152 - val_accuracy: 0.5000\n",
      "Epoch 231/300\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.4815 - accuracy: 0.8111 - val_loss: 1.3988 - val_accuracy: 0.4667\n",
      "Epoch 232/300\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.3569 - accuracy: 0.8679 - val_loss: 1.3599 - val_accuracy: 0.5000\n",
      "Epoch 233/300\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.4084 - accuracy: 0.7830 - val_loss: 1.3332 - val_accuracy: 0.5000\n",
      "Epoch 234/300\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.3440 - accuracy: 0.8392 - val_loss: 1.3194 - val_accuracy: 0.5000\n",
      "Epoch 235/300\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.2996 - accuracy: 0.8648 - val_loss: 1.3202 - val_accuracy: 0.5333\n",
      "Epoch 236/300\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.2806 - accuracy: 0.9210 - val_loss: 1.3187 - val_accuracy: 0.5333\n",
      "Epoch 237/300\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.3833 - accuracy: 0.8124 - val_loss: 1.3076 - val_accuracy: 0.5333\n",
      "Epoch 238/300\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.3777 - accuracy: 0.7764 - val_loss: 1.3003 - val_accuracy: 0.5667\n",
      "Epoch 239/300\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.5831 - accuracy: 0.8059 - val_loss: 1.2961 - val_accuracy: 0.5667\n",
      "Epoch 240/300\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.4613 - accuracy: 0.8004 - val_loss: 1.2946 - val_accuracy: 0.5667\n",
      "Epoch 241/300\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.4128 - accuracy: 0.8312 - val_loss: 1.2971 - val_accuracy: 0.5333\n",
      "Epoch 242/300\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.3079 - accuracy: 0.8471 - val_loss: 1.2965 - val_accuracy: 0.5333\n",
      "Epoch 243/300\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.3262 - accuracy: 0.8231 - val_loss: 1.2911 - val_accuracy: 0.5333\n",
      "Epoch 244/300\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.3804 - accuracy: 0.9023 - val_loss: 1.2894 - val_accuracy: 0.5667\n",
      "Epoch 245/300\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.3481 - accuracy: 0.8585 - val_loss: 1.2937 - val_accuracy: 0.5333\n",
      "Epoch 246/300\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.3823 - accuracy: 0.7913 - val_loss: 1.3071 - val_accuracy: 0.5333\n",
      "Epoch 247/300\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.3577 - accuracy: 0.7960 - val_loss: 1.3162 - val_accuracy: 0.5333\n",
      "Epoch 248/300\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.3040 - accuracy: 0.8356 - val_loss: 1.3340 - val_accuracy: 0.5333\n",
      "Epoch 249/300\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.2426 - accuracy: 0.8494 - val_loss: 1.3370 - val_accuracy: 0.5333\n",
      "Epoch 250/300\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.3331 - accuracy: 0.8411 - val_loss: 1.3450 - val_accuracy: 0.5333\n",
      "Epoch 251/300\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.3518 - accuracy: 0.8022 - val_loss: 1.3607 - val_accuracy: 0.5000\n",
      "Epoch 252/300\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.2906 - accuracy: 0.7936 - val_loss: 1.3780 - val_accuracy: 0.5000\n",
      "Epoch 253/300\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.3103 - accuracy: 0.8405 - val_loss: 1.3848 - val_accuracy: 0.5000\n",
      "Epoch 254/300\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.3439 - accuracy: 0.7778 - val_loss: 1.3955 - val_accuracy: 0.5000\n",
      "Epoch 255/300\n",
      "4/4 [==============================] - 0s 115ms/step - loss: 0.2942 - accuracy: 0.8642 - val_loss: 1.3999 - val_accuracy: 0.4667\n",
      "Epoch 256/300\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.4233 - accuracy: 0.7806 - val_loss: 1.4055 - val_accuracy: 0.4667\n",
      "Epoch 257/300\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.3582 - accuracy: 0.8246 - val_loss: 1.4156 - val_accuracy: 0.4667\n",
      "Epoch 258/300\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.2441 - accuracy: 0.8932 - val_loss: 1.4199 - val_accuracy: 0.4667\n",
      "Epoch 259/300\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.2077 - accuracy: 0.8976 - val_loss: 1.4156 - val_accuracy: 0.4667\n",
      "Epoch 260/300\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.1500 - accuracy: 0.9200 - val_loss: 1.4131 - val_accuracy: 0.4667\n",
      "Epoch 261/300\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.3632 - accuracy: 0.8502 - val_loss: 1.4121 - val_accuracy: 0.4667\n",
      "Epoch 262/300\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.3426 - accuracy: 0.8317 - val_loss: 1.4149 - val_accuracy: 0.4667\n",
      "Epoch 263/300\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.3291 - accuracy: 0.8549 - val_loss: 1.4191 - val_accuracy: 0.4667\n",
      "Epoch 264/300\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.3116 - accuracy: 0.7918 - val_loss: 1.4212 - val_accuracy: 0.4667\n",
      "Epoch 265/300\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.2300 - accuracy: 0.8624 - val_loss: 1.4243 - val_accuracy: 0.4667\n",
      "Epoch 266/300\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.1717 - accuracy: 0.9192 - val_loss: 1.4208 - val_accuracy: 0.4667\n",
      "Epoch 267/300\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.3773 - accuracy: 0.8061 - val_loss: 1.4181 - val_accuracy: 0.4667\n",
      "Epoch 268/300\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.3969 - accuracy: 0.8124 - val_loss: 1.4258 - val_accuracy: 0.4667\n",
      "Epoch 269/300\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.3417 - accuracy: 0.8538 - val_loss: 1.4316 - val_accuracy: 0.4667\n",
      "Epoch 270/300\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.2473 - accuracy: 0.8252 - val_loss: 1.4292 - val_accuracy: 0.4667\n",
      "Epoch 271/300\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.2867 - accuracy: 0.8306 - val_loss: 1.4262 - val_accuracy: 0.4667\n",
      "Epoch 272/300\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.2795 - accuracy: 0.8486 - val_loss: 1.4227 - val_accuracy: 0.5000\n",
      "Epoch 273/300\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.2932 - accuracy: 0.8299 - val_loss: 1.4153 - val_accuracy: 0.5000\n",
      "Epoch 274/300\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.2468 - accuracy: 0.8635 - val_loss: 1.4101 - val_accuracy: 0.5000\n",
      "Epoch 275/300\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.2614 - accuracy: 0.8424 - val_loss: 1.4120 - val_accuracy: 0.5000\n",
      "Epoch 276/300\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.3997 - accuracy: 0.8067 - val_loss: 1.4030 - val_accuracy: 0.5000\n",
      "Epoch 277/300\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.3222 - accuracy: 0.7952 - val_loss: 1.3992 - val_accuracy: 0.5000\n",
      "Epoch 278/300\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.4998 - accuracy: 0.8153 - val_loss: 1.3952 - val_accuracy: 0.5000\n",
      "Epoch 279/300\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.1894 - accuracy: 0.8984 - val_loss: 1.3946 - val_accuracy: 0.5000\n",
      "Epoch 280/300\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.1735 - accuracy: 0.8989 - val_loss: 1.3995 - val_accuracy: 0.5000\n",
      "Epoch 281/300\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.2769 - accuracy: 0.8413 - val_loss: 1.4111 - val_accuracy: 0.5000\n",
      "Epoch 282/300\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.2833 - accuracy: 0.8304 - val_loss: 1.4182 - val_accuracy: 0.5000\n",
      "Epoch 283/300\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.2622 - accuracy: 0.8874 - val_loss: 1.4128 - val_accuracy: 0.5000\n",
      "Epoch 284/300\n",
      "4/4 [==============================] - 0s 115ms/step - loss: 0.2522 - accuracy: 0.8687 - val_loss: 1.4122 - val_accuracy: 0.5000\n",
      "Epoch 285/300\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.3061 - accuracy: 0.8663 - val_loss: 1.4107 - val_accuracy: 0.5333\n",
      "Epoch 286/300\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.2951 - accuracy: 0.8695 - val_loss: 1.4111 - val_accuracy: 0.5333\n",
      "Epoch 287/300\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.2079 - accuracy: 0.8817 - val_loss: 1.4167 - val_accuracy: 0.5333\n",
      "Epoch 288/300\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.2305 - accuracy: 0.8851 - val_loss: 1.4254 - val_accuracy: 0.5333\n",
      "Epoch 289/300\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.4379 - accuracy: 0.8471 - val_loss: 1.4365 - val_accuracy: 0.5333\n",
      "Epoch 290/300\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.3395 - accuracy: 0.8549 - val_loss: 1.4423 - val_accuracy: 0.5333\n",
      "Epoch 291/300\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.1849 - accuracy: 0.8687 - val_loss: 1.4442 - val_accuracy: 0.5333\n",
      "Epoch 292/300\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.1758 - accuracy: 0.8958 - val_loss: 1.4427 - val_accuracy: 0.5667\n",
      "Epoch 293/300\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.3312 - accuracy: 0.8546 - val_loss: 1.4458 - val_accuracy: 0.5667\n",
      "Epoch 294/300\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.3754 - accuracy: 0.9145 - val_loss: 1.4542 - val_accuracy: 0.5333\n",
      "Epoch 295/300\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.2813 - accuracy: 0.8880 - val_loss: 1.4654 - val_accuracy: 0.5333\n",
      "Epoch 296/300\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.2093 - accuracy: 0.8635 - val_loss: 1.4772 - val_accuracy: 0.5000\n",
      "Epoch 297/300\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.3590 - accuracy: 0.8166 - val_loss: 1.4887 - val_accuracy: 0.5000\n",
      "Epoch 298/300\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.2476 - accuracy: 0.8531 - val_loss: 1.5005 - val_accuracy: 0.5000\n",
      "Epoch 299/300\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.3437 - accuracy: 0.8403 - val_loss: 1.4848 - val_accuracy: 0.5000\n",
      "Epoch 300/300\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.5183 - accuracy: 0.8262 - val_loss: 1.4607 - val_accuracy: 0.5000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1bce8cae0b8>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras import optimizers\n",
    "from kerastuner.tuners import BayesianOptimization, RandomSearch\n",
    "from keras.callbacks import EarlyStopping\n",
    "early_stopping = EarlyStopping(patience=10, mode='auto')\n",
    "\n",
    "adams = optimizers.Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=1e-6, amsgrad=False)\n",
    "early_stopping = EarlyStopping(patience=20, mode='auto')\n",
    "#epoch 23 works best\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=adams,\n",
    "              metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, epochs=300, validation_data=(X_test, y_test),class_weight=d_class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "850b9e5d-5d02-429d-a553-5d9df00a4cd3",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found array with dim 3. StandardScaler expected <= 2.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-30-c1e3198e6101>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mscaler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mscaler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mx_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf2.4\\lib\\site-packages\\sklearn\\preprocessing\\_data.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    728\u001b[0m         \u001b[1;31m# Reset internal state before fitting\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    729\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 730\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpartial_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    731\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    732\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpartial_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf2.4\\lib\\site-packages\\sklearn\\preprocessing\\_data.py\u001b[0m in \u001b[0;36mpartial_fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    766\u001b[0m         X = self._validate_data(X, accept_sparse=('csr', 'csc'),\n\u001b[0;32m    767\u001b[0m                                 \u001b[0mestimator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFLOAT_DTYPES\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 768\u001b[1;33m                                 force_all_finite='allow-nan', reset=first_call)\n\u001b[0m\u001b[0;32m    769\u001b[0m         \u001b[0mn_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    770\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf2.4\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    419\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    420\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'no_validation'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 421\u001b[1;33m             \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    422\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    423\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf2.4\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf2.4\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[0;32m    658\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mallow_nd\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    659\u001b[0m             raise ValueError(\"Found array with dim %d. %s expected <= 2.\"\n\u001b[1;32m--> 660\u001b[1;33m                              % (array.ndim, estimator_name))\n\u001b[0m\u001b[0;32m    661\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    662\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Found array with dim 3. StandardScaler expected <= 2."
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(x_test)\n",
    "x_test = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "edfb434f-e1a0-464a-8fe4-0163fe41b4a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(471, 35, 20)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "63334f2c-691b-4a46-9200-ae1c6be92bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = x_test.reshape((471, 35, 20))\n",
    "yhat = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bae3945f-0861-4c56-a6d3-cf3277f8879e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels = pd.read_csv('content/sample_submission.csv')\n",
    "for i in range(0, 471):\n",
    "    if yhat[i][0] > yhat[i][1] and yhat[i][0] > yhat[i][2]:\n",
    "        test_labels['DIAG_NM'][i] = 'CN'\n",
    "    elif yhat[i][1] > yhat[i][0] and yhat[i][1] > yhat[i][2]:\n",
    "        test_labels['DIAG_NM'][i] = 'Dem'\n",
    "    elif yhat[i][2] > yhat[i][1] and yhat[i][2] > yhat[i][0]:\n",
    "        test_labels['DIAG_NM'][i] = 'MCI'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3dccb299-0d02-44fa-8bd2-05cb27fde2a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels.to_csv('content/predict25.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e98594ae-3220-460d-b472-03fb0fb8375a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f8f5ae7-9457-4250-8c7b-44bae9548fa1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2.4",
   "language": "python",
   "name": "tf2.4"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
